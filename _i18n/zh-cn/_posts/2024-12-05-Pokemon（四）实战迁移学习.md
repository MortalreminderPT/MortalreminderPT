---
layout: post
title: Pokemon（四）实战迁移学习
description:
date: 2024-12-05 21:45:12 +0800
image: https://miro.medium.com/v2/0*Y9_WRbhh2ZanZGRP.png
tags:
- Algorithm
- Python
- Pytorch
category: ['Algorithm']
---

1. 目录
{:toc}

在前几篇博客中，我们已经详细介绍了如何使用PyTorch自定义`Dataset`类来加载和预处理Pokemon图像数据集，构建一个简化版的ResNet18模型，并进行模型的训练、验证及测试。本篇博客将重点探讨**迁移学习（Transfer Learning）**在Pokemon图像分类任务中的应用，通过利用预训练的ResNet18模型，进一步提升模型的性能和训练效率。

## 迁移学习概述

**迁移学习**是一种机器学习方法，通过利用在大型数据集（如ImageNet）上预训练的模型，将所学到的特征和知识迁移到新的、相关的任务中。迁移学习在以下场景中特别有效：

- **数据量有限**：目标任务的数据不足以从头训练一个深层网络时，迁移学习可以利用预训练模型的特征提取能力。
- **训练时间有限**：预训练模型已经学习了丰富的特征，可以减少训练时间。
- **性能提升**：在许多任务中，迁移学习能够显著提升模型的性能，尤其是在目标任务与预训练任务相关性较高时。

在本项目中，我们将使用`torchvision`库中预训练的ResNet18模型，并对其进行微调，以适应Pokemon图像分类任务。

## 迁移学习与普通训练的区别

在前面的博客中，我们从头开始构建并训练了一个自定义的ResNet18模型。然而，这种方法需要大量的数据和计算资源，且训练时间较长。迁移学习通过以下方式优化了这一过程：

1. **利用预训练权重**：使用在大规模数据集上预训练的模型权重，减少了模型从零开始学习的需求。
2. **修改输出层**：根据目标任务的类别数调整模型的最后一层，以适应新的分类任务。
3. **加速训练**：预训练模型已经具备了良好的特征提取能力，可以缩短训练时间并提高模型性能。

以下是迁移学习部分的关键代码，我们将重点解析这些不同于普通训练方式的部分。

```python
from torchvision.models import resnet18
from .utils import Flatten

# 加载预训练的ResNet18模型
trained_model = resnet18(pretrained=True)

# 修改模型结构：去除最后一层，全连接层，并添加自定义层
model = nn.Sequential(
    *list(trained_model.children())[:-1],  # 去除ResNet18的最后一个全连接层
    Flatten(),                              # 将多维张量展平为一维向量
    nn.Linear(512, 5)                       # 添加新的全连接层，输出类别数为5
).to(device)
```

### 加载预训练模型

```python
from torchvision.models import resnet18

# 加载预训练的ResNet18模型
trained_model = resnet18(pretrained=True)
```

**解析：**

- **预训练参数**：通过设置`pretrained=True`，我们加载了在ImageNet数据集上预训练的ResNet18模型。这些预训练权重包含了丰富的图像特征信息，有助于在新任务中快速收敛。
- **模型架构**：预训练模型包含了完整的ResNet18架构，包括多个卷积层、批归一化层、残差连接以及最后的全连接层。

### 修改模型结构

```python
from .utils import Flatten

# 修改模型结构：去除最后一层，全连接层，并添加自定义层
model = nn.Sequential(
    *list(trained_model.children())[:-1],  # 去除ResNet18的最后一个全连接层
    Flatten(),                              # 将多维张量展平为一维向量
    nn.Linear(512, 5)                       # 添加新的全连接层，输出类别数为5
).to(device)
```

**解析：**

1. **去除最后一层**：
    - `*list(trained_model.children())[:-1]`：获取ResNet18模型的所有子模块，去除最后一个全连接层（`fc`层）。这一步保留了ResNet18的特征提取部分。

2. **添加Flatten层**：
    - `Flatten()`：自定义的Flatten层，用于将多维张量展平为一维向量。假设输入形状为`[batch_size, 512, 1, 1]`，展平后为`[batch_size, 512]`。
    - **代码示例**（假设`Flatten`类定义如下）：
      ```python
      import torch.nn as nn

      class Flatten(nn.Module):
          def forward(self, x):
              return x.view(x.size(0), -1)
      ```

3. **添加新的全连接层**：
    - `nn.Linear(512, 5)`：根据目标任务的类别数（5类Pokemon），添加一个新的全连接层，将512维的特征映射到5个类别。

## 训练结果

迁移学习的训练流程在整体结构上与普通训练方式相似，这里直接给出训练结果：

```
best acc: 0.9871244635193133 best epoch: 9
loaded from ckpt!
test acc: 0.9399141630901288
```

<img src='\images\posts\train-transfer.png'
  style="
    display: block;
    margin-left: auto;
    margin-right: auto; 
    zoom:100%;" />

可见相比于从0开始训练，采用迁移学习将测试集准确率提高了5%。