---
layout: post
title: 使用VAE重建MNIST数据集
description:
date: 2024-12-08 19:12:54 +1100
image: https://about.fb.com/wp-content/uploads/2022/09/PyTorch-Foundation-Launch_Header.jpg
tags:
- Algorithm
- Python
- Pytorch
category: ['Algorithm']
---

1. 目录
{:toc}

在前面的博客中，我们介绍了自encoder（Autoencoder），这是一种用于无监督学习的神经网络架构，广泛应用于数据降维、特征学习和数据生成等任务。变分自encoder（Variational Autoencoder，简称VAE）是自encoder的一个扩展，结合了概率图模型的思想，能够生成更加连贯且具有高质量的样本。

这是一种生成模型，通过学习数据的潜在分布来生成新样本。与传统自encoder不同，VAE在encoder输出的是一个潜在空间的分布参数（均值μ和标准差σ），而不是一个固定的向量。这使得VAE能够通过采样潜在变量来生成多样化的输出。

这篇博客将使用PyTorch实现VAE并在MNIST数据集上进行图像重建。

主要步骤包括：

1. **Encoder**：将输入数据映射到潜在空间的均值和标准差。
2. **Reparameterization**：通过均值和标准差采样潜在变量，以便模型可以进行反向传播。
3. **Decoder**：将潜在变量映射回原始数据空间，生成重构数据。
4. **损失函数**：结合重构误差和KL散度，优化模型。

## 项目结构

本项目包含两个主要部分：

1. **主训练脚本**：负责数据加载、模型训练、测试和结果可视化。
2. **VAE模型定义**：定义VAE的结构，包括encoder和decoder。

```plaintext
project/
│
├── main.py          # 主训练脚本
└── vae.py           # VAE模型定义
```

## 代码解析

### 定义VAE模型

在`vae.py`中，我们定义了VAE模型。

```python
import torch
from torch import nn

class VAE(nn.Module):

    def __init__(self):
        super(VAE, self).__init__()

        # encoder：输入维度784（28x28图像展平） -> 隐藏层256 -> 隐藏层64 -> 输出层20（包含μ和σ各10维）
        self.encoder = nn.Sequential(
            nn.Linear(784, 256),
            nn.ReLU(),
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, 20),
            nn.ReLU()
        )
        # decoder：潜在变量10维 -> 隐藏层64 -> 隐藏层256 -> 输出层784
        self.decoder = nn.Sequential(
            nn.Linear(10, 64),
            nn.ReLU(),
            nn.Linear(64, 256),
            nn.ReLU(),
            nn.Linear(256, 784),
            nn.Sigmoid()
        )

        self.criteon = nn.MSELoss()

    def forward(self, x):
        """
        :param x: [b, 1, 28, 28]
        :return: 重构后的图像和KL散度
        """
        batchsz = x.size(0)
        # 将图像展平为[b, 784]
        x = x.view(batchsz, 784)
        # encoder输出[h_, [b, 20]]，包括μ和σ
        h_ = self.encoder(x)
        # 将h_拆分为μ和σ，每个都是[b, 10]
        mu, sigma = h_.chunk(2, dim=1)
        # Reparameterization技巧：h = μ + σ * ε，其中ε ~ N(0,1)
        h = mu + sigma * torch.randn_like(sigma)

        # decoder生成重构图像
        x_hat = self.decoder(h)
        # 将重构图像恢复为[b, 1, 28, 28]
        x_hat = x_hat.view(batchsz, 1, 28, 28)

        # 计算KL散度，P：ε ~ N(0,1)；q：N(mu, sigma)
        kld = 0.5 * torch.sum(
            torch.pow(mu, 2) +
            torch.pow(sigma, 2) -
            torch.log(1e-8 + torch.pow(sigma, 2)) - 1
        ) / (batchsz * 28 * 28)

        return x_hat, kld
```

#### 模型结构

- **encoder（Encoder）**：
    - 输入层：784维（28x28图像展平）。
    - 隐藏层1：256个神经元，激活函数ReLU。
    - 隐藏层2：64个神经元，激活函数ReLU。
    - 输出层：20维，包含均值μ和标准差σ各10维，激活函数ReLU。

- **decoder（Decoder）**：
    - 输入层：10维潜在变量。
    - 隐藏层1：64个神经元，激活函数ReLU。
    - 隐藏层2：256个神经元，激活函数ReLU。
    - 输出层：784维，激活函数Sigmoid，将输出映射到[0,1]区间。

#### 前向传播

1. **展平输入**：将输入图像从`[b, 1, 28, 28]`展平为`[b, 784]`。
2. **Encode**：通过encoder生成隐变量的均值μ和标准差σ。
3. **Reparameterization**：使用`μ + σ * ε`采样潜在变量，其中`ε ~ N(0,1)`。
4. **Decode**：通过decoder生成重构图像`x_hat`。
5. **计算KL散度**：衡量潜在分布与标准正态分布的差异。

### 训练和测试流程

在`main.py`中，我们定义了训练和测试的主流程。

```python
import torch
from torch.utils.data import DataLoader
from torch import nn, optim
from torchvision import transforms, datasets

from vae import VAE

import visdom


def main():
    # 加载MNIST训练数据
    mnist_train = datasets.MNIST('.', True, transform=transforms.Compose([
        transforms.ToTensor()
    ]), download=True)
    mnist_train = DataLoader(mnist_train, batch_size=32, shuffle=True)

    # 加载MNIST测试数据
    mnist_test = datasets.MNIST('.', False, transform=transforms.Compose([
        transforms.ToTensor()
    ]), download=True)
    mnist_test = DataLoader(mnist_test, batch_size=32, shuffle=True)

    # 查看一个批次的数据形状
    x, _ = iter(mnist_train).next()
    print('x:', x.shape)

    # 设置设备
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = VAE().to(device)
    criteon = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-3)
    print(model)

    # 需要启动Visdom
    # 在终端运行: python -m visdom.server
    viz = visdom.Visdom()

    for epoch in range(1000):

        model.train()
        for batchidx, (x, _) in enumerate(mnist_train):
            # [b, 1, 28, 28]
            x = x.to(device)

            x_hat, kld = model(x)
            loss = criteon(x_hat, x)

            if kld is not None:
                elbo = - loss - 1.0 * kld
                loss = - elbo

            # 反向传播
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        print(epoch, 'loss:', loss.item(), 'kld:', kld.item())

        # 测试阶段
        model.eval()
        x, _ = iter(mnist_test).next()
        x = x.to(device)
        with torch.no_grad():
            x_hat, kld = model(x)
        # 可视化原图和重构图
        viz.images(x.cpu(), nrow=8, win='x', opts=dict(title='x'))
        viz.images(x_hat.cpu(), nrow=8, win='x_hat', opts=dict(title='x_hat'))


if __name__ == '__main__':
    main()
```

#### 详细步骤

1. **数据加载**：
    - 使用`torchvision.datasets.MNIST`加载MNIST数据集。
    - 使用`DataLoader`包装训练和测试数据，设置批次大小为32，训练数据打乱顺序。

2. **设备设置**：
    - 检查是否有可用的GPU，优先使用CUDA设备。

3. **模型、损失函数和优化器**：
    - 实例化VAE模型并移动到设备。
    - 使用均方误差（MSE）作为重构损失函数。
    - 使用Adam优化器，学习率设置为1e-3。

4. **可视化设置**：
    - 使用Visdom进行实时可视化。
    - **注意**：在运行代码前，需要在终端启动Visdom服务器：
      ```bash
      python -m visdom.server
      ```

5. **训练循环**：
    - 训练1000个epoch。
    - 对每个批次：
        - 将输入移动到设备。
        - 前向传播，获取重构图像`x_hat`和KL散度`kld`。
        - 计算损失：
            - 如果存在`kld`，则计算证据下界（ELBO）`elbo = - loss - 1.0 * kld`。
            - 最终损失为`-ELBO`。
        - 反向传播和优化。
    - 每个epoch结束后，打印损失和KL散度。

6. **测试和可视化**：
    - 在每个epoch结束后，使用测试集中的一个批次进行测试。
    - 将原图和重构图通过Visdom进行可视化。

## 运行效果

大约经过50个epoch后，模型重建的图片效果如下：

<img src='\images\posts\vae_practice.jpg'
  style="
    display: block;
    margin-left: auto;
    margin-right: auto; 
    zoom:100%;" />

可以发现模型大致可以完成正确的重建，但部分数据还是存在重建数字错误的问题，这可能和训练时间和模型复杂程度有关。

## 总结

本文介绍了如何使用PyTorch实现一个VAE模型，并在MNIST数据集上进行图像重建。通过VAE，我们不仅能够重构输入图像，还能探索数据的潜在分布。VAE在生成模型、异常检测和半监督学习等领域具有广泛的应用前景。